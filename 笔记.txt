运行环境：

python == 3.6
keras == 2.1.5
tensorflow == 1.6.0
opencv == 3.4.2

1、昨天晚上我灵机一动，为什么非得用YOLOv3来进行车牌号检测，明明语义分割的代码训练起来更简单，而且需要的数据集也很少，几千张图片足以完全搞定，而且当时u-net跑出来的效果绝佳，按道理检测出的轮廓应该很准确，因为它训练时有监督给出了更多的信息！！！

最重要的是，对于车牌号检测的语义分割，由于车牌轮廓是一个标准矩形，我们完全没必要去标注样本，直接对那个bounding box赋值即可，这大大节省了标注人力物力。



2、首先我按照这种思路，把CCPD数据集resize成u-net的(64, 96)尺寸：

训练起来真的很快，只用10个epoch，每个几分钟就足以学习得很好很好！！！测试测试集图片时，效果完美！！！对整张图片车牌号轮廓的把握十分精准，没有再出现残缺和定位错误的情况。昨天这个意外的想法，一下子就把六月份困扰我多时的问题解决了！！！

最棒的是，u-net模型比起YOLO这种巨无霸要简单的多了多，接入视频流时处理更流畅，轮廓检测效果也更完美，位置定位效果也更精确。

唯一出的问题是，缺乏可信度预测。即使整张图片中没有车牌，算法还是会倾向于输出一部分像素作为检测结果，这个问题还没很好的解决思路，按道理不会出现这种样子啊。

我拿训练的权重去跑当初停车场的视频，效果还可，就是边沿框略大，我觉得可以通过，把输入视频resize到训练尺寸，减少形变可以改善。

我拿训练的权重去接usb摄像头，实时输出的检测效果完美！！！！！



3、我觉得原u-net的(64, 96)尺寸太小了，不足以精确描述车牌位置。
于是把尺寸全放大了四倍，扩充到(256, 384)尺寸，结果跑训练的时候，直接内存不够用，看来语义分割真的很吃内存。

于是把u-net扩充到(192, 192)尺寸，于是可以继续训练了。

我训练了10个epoch，效果极佳，而且前面出现的问题不再存在了！！！！！！

首先对于测试集图片，精度达到了99%，而且边缘轮廓极准！！！
然后对于停车场拍的视频流，从头到尾无跳动，检测清晰，而且边缘轮廓很准，一直超精确！！！
最后对于连接USB摄像头，检测效果更佳无敌。但凡出现合适的车牌号图片，检测就很清晰。如果图片中啥都没有，它只会输出一整个大框，十分稳定。

